{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def unzip_file(zip_path, extract_to='.'):\n",
        "    \"\"\"\n",
        "    Unzips a file to the specified directory.\n",
        "\n",
        "    :param zip_path: Path to the .zip file\n",
        "    :param extract_to: Directory where files will be extracted (default: current directory)\n",
        "    \"\"\"\n",
        "    if not zipfile.is_zipfile(zip_path):\n",
        "        print(\"Error: Not a valid ZIP file.\")\n",
        "        return\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "        print(f\"Extracted '{zip_path}' to '{extract_to}'.\")\n",
        "\n",
        "# Example Usage\n",
        "zip_path = \"example.zip\"  # Change this to your ZIP file path\n",
        "extract_to = \"output_folder\"  # Change this to your desired extraction folder\n",
        "unzip_file(zip_path, extract_to)\n"
      ],
      "metadata": {
        "id": "s9pKciJaHLD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy pandas matplotlib opencv-python tensorflow scikit-learn keras-tuner\n"
      ],
      "metadata": {
        "id": "nSCpjBmlHZzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy pandas opencv-python tensorflow matplotlib seaborn scikit-learn keras\n"
      ],
      "metadata": {
        "id": "NU0XQ-A8qkkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Uvg-FqDHntng",
        "outputId": "49d26290-1348-449b-f70b-d87750dafd16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define paths\n",
        "TRAIN_PATH = '/content/drive/MyDrive/data/train'\n",
        "VALID_PATH = '/content/drive/MyDrive/data/valid'\n",
        "TEST_PATH = '/content/drive/MyDrive/data/test'\n",
        "\n",
        "# Image parameters\n",
        "TARGET_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 6\n",
        "\n",
        "# Class names\n",
        "class_names = {\n",
        "    0: 'DangerousDriving',\n",
        "    1: 'Distracted',\n",
        "    2: 'Drinking',\n",
        "    3: 'SafeDriving',\n",
        "    4: 'SleepyDriving',\n",
        "    5: 'Yawn'\n",
        "}\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, TARGET_SIZE)\n",
        "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
        "    return image\n",
        "\n",
        "def prepare_dataset(annotations_df, base_path):\n",
        "    images, labels = [], []\n",
        "    for _, row in annotations_df.iterrows():\n",
        "        image_path = os.path.join(base_path, row['image_name'])\n",
        "        image = preprocess_image(image_path)\n",
        "        images.append(image)\n",
        "        labels.append(row['class_id'])\n",
        "    return np.array(images), tf.keras.utils.to_categorical(labels, NUM_CLASSES)\n",
        "\n",
        "# Data augmentation\n",
        "data_augmentation = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "def create_model(learning_rate=0.001, dropout_rate=0.5):\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Hyperparameter tuning\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "param_grid = {\n",
        "    'learning_rate': [0.0001, 0.001, 0.01],\n",
        "    'dropout_rate': [0.3, 0.5, 0.7],\n",
        "    'batch_size': [16, 32, 64],\n",
        "    'epochs': [10, 20]\n",
        "}\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Best parameters: {grid_result.best_params_}\")\n",
        "\n",
        "# Train final model with best parameters\n",
        "best_params = grid_result.best_params_\n",
        "final_model = create_model(learning_rate=best_params['learning_rate'], dropout_rate=best_params['dropout_rate'])\n",
        "final_model.fit(\n",
        "    data_augmentation.flow(X_train, y_train, batch_size=best_params['batch_size']),\n",
        "    epochs=best_params['epochs'],\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[\n",
        "        EarlyStopping(patience=5, monitor='val_loss', restore_best_weights=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1),\n",
        "        ModelCheckpoint('best_imagenet_model.keras', save_best_only=True, monitor='val_loss')\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Confusion Matrix & Classification Report\n",
        "y_pred = final_model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "print(\"Classification Report:\\n\", classification_report(y_true, y_pred_classes))\n",
        "\n",
        "# Plot confusion matrix\n",
        "def plot_confusion_matrix(cm, classes):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "plot_confusion_matrix(conf_matrix, list(class_names.values()))\n",
        "\n",
        "def plot_predictions(model, test_images, test_labels, num_samples=10):\n",
        "    indices = np.random.choice(len(test_images), num_samples, replace=False)\n",
        "    sample_images = test_images[indices]\n",
        "    sample_labels = test_labels[indices]\n",
        "    predictions = model.predict(sample_images)\n",
        "\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    for i in range(num_samples):\n",
        "        plt.subplot(2, 5, i+1)\n",
        "        plt.imshow(sample_images[i].astype('float32') / 255.0)\n",
        "        actual = class_names[np.argmax(sample_labels[i])]\n",
        "        predicted = class_names[np.argmax(predictions[i])]\n",
        "        color = 'green' if actual == predicted else 'red'\n",
        "        plt.title(f\"Actual: {actual}\\nPredicted: {predicted}\", color=color)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display 10 test samples with predictions\n",
        "plot_predictions(final_model, X_test, y_test)\n"
      ],
      "metadata": {
        "id": "G7avE3T1qHSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import keras_tuner as kt\n",
        "\n",
        "# Define constants\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "NUM_CLASSES = 5  # Adjust based on the dataset\n",
        "\n",
        "def build_model(hp):\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False  # Freezing the base model\n",
        "\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(hp.Int('units', min_value=64, max_value=512, step=64), activation='relu')(x)\n",
        "    x = Dropout(hp.Float('dropout', 0.2, 0.5, step=0.1))(x)\n",
        "    output = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', [1e-4, 1e-3, 1e-2])),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'dataset/train',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    'dataset/train',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Hyperparameter tuning\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    directory='tuner_results',\n",
        "    project_name='resnet50_tuning'\n",
        ")\n",
        "\n",
        "tuner.search(train_generator, validation_data=val_generator, epochs=10)\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Build and train the best model\n",
        "best_model = build_model(best_hps)\n",
        "best_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[EarlyStopping(monitor='val_loss', patience=3), ModelCheckpoint('best_model.h5', save_best_only=True)]\n",
        ")\n",
        "\n",
        "# Fine-tuning\n",
        "base_model = best_model.layers[0]\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:100]:  # Freezing first 100 layers\n",
        "    layer.trainable = False\n",
        "\n",
        "best_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "best_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[EarlyStopping(monitor='val_loss', patience=3), ModelCheckpoint('fine_tuned_model.h5', save_best_only=True)]\n",
        ")\n"
      ],
      "metadata": {
        "id": "ITMfLboXoU0n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}